{"cells":[{"cell_type":"markdown","metadata":{"id":"gtKoe0Hl_Jxa"},"source":["# Семинар 9 - Методы построения оптического потока по последовательности изображений\n","\n","***"]},{"cell_type":"markdown","metadata":{"id":"8NxqV9z2_Jxc"},"source":["Источник - https://habr.com/ru/post/201406/\n","\n","$\\textbf{Task statement}$: Оптический поток (ОП) – изображение видимого движения, представляющее собой сдвиг каждой точки (пикселя) между двумя изображениями.\n","\n","По сути, он представляет собой поле скоростей. Суть ОП в том, что для каждой точки изображения $I_{t_0} (\\vec{r})$ находится такой вектор сдвига $\\delta \\vec{r}$, чтобы было соответсвие между исходной точкой и точкой на следущем фрейме $I_{t_1} (\\vec{r} + \\delta \\vec{r})$. В качестве метрики соответвия берут близость интенсивности пикселей, беря во внимание маленькую разницу по времени между кадрами: $\\delta{t} = t_{1} - t_{0}$. В более точных методах точку можно привязывать к объекту на основе, например, выделения ключевых точек, а также считать градиенты вокруг точки, лапласианы и проч.\n","\n","$\\textbf{For what}$: Определение собственной скорости, Определение локализации, Улучшение методов трекинга объектов, сегментации, Детектирование событий, Сжатие видеопотока и проч.\n","\n","![](data/tennis.png)\n","\n","Разделяют 2 вида оптического потока - плотный (dense) [Farneback method, neural nets], работающий с целым изображением, и выборочный (sparse) [Lucas-Kanade method], работающий с ключевыми точками"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"tags":[],"id":"RfJyhbN1_Jxe"},"outputs":[],"source":["!wget https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O data/slow_traffic_small.mp4"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"SG0l-4rw_Jxf","executionInfo":{"status":"ok","timestamp":1713207302047,"user_tz":-180,"elapsed":627,"user":{"displayName":"Julia Bel","userId":"09344534935963523050"}}},"outputs":[],"source":["import cv2\n","from tqdm import tqdm\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import IPython\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"pvCAOrii_Jxg"},"source":["## Lucas-Kanade (sparse)\n","\n","Пусть $I_{1} = I(x, y, t_{1})$ интенсивность в некоторой точке (x, y) на первом изображении (т. е. в момент времени t). На втором изображении эта точка сдвинулась на (dx, dy), при этом прошло время dt, тогда $I_{2} = I(x + dx, y + dx, t_{1} + dt) \\approx I_{1} + I_{x}dx + I_{y}dy +  I_{t}dt$. Из постановки задачи следует, что интенсивность пикселя не изменилась, тогда $I_{1} = I_{2}$. Далее определяем $dx, dy$.\n","\n","Самое простое решение проблемы – алгоритм Лукаса-Канаде. У нас же на изображении объекты размером больше 1 пикселя, значит, скорее всего, в окрестности текущей точки у других точек будут примерно такие же сдвиги. Поэтому мы возьмем окно вокруг этой точки и минимизируем (по МНК) в нем суммарную погрешность с весовыми коэффициентами, распределенными по Гауссу, то есть так, чтобы наибольший вес имели пиксели, ближе всего находящиеся к исследуемому.\n","\n","**Полезные материалы:**\n","- цикл видео-лекций от First Principles of Computer Vision, посвященный Optical Flow и алгоритму Lucas-Kanade: https://youtube.com/playlist?list=PL2zRqk16wsdoYzrWStffqBAoUY8XdvatV"]},{"cell_type":"markdown","metadata":{"id":"0etXl1kS_Jxg"},"source":["### Вопрос 1\n","\n","В `cv2.calcOpticalFlowPyrLK` есть параметр, отвечающий за ImagePiramyd. Зачем нужна пирамида изображений в случае вычисления оптического потока?\n","\n","**Ответ:**\n","\n","Используя несколько уровней разрешения, алгоритм сначала фиксирует крупные движения в более крупном масштабе, что обеспечивает робастность, а затем уточняет отслеживание движений в более мелких масштабах для повышения точности."]},{"cell_type":"markdown","metadata":{"id":"ZhQICrWV_Jxh"},"source":["### Задание 1\n","\n","Напишите реализацию Лукаса-Канаде c помощью numpy и cv2. Сравните с реализацией `cv2.calcOpticalFlowPyrLK`."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"LF1_dmvk_Jxh","executionInfo":{"status":"ok","timestamp":1713208858547,"user_tz":-180,"elapsed":318,"user":{"displayName":"Julia Bel","userId":"09344534935963523050"}}},"outputs":[],"source":["def get_derivative_x(img, keypoint, winSize):\n","    \"\"\"Compute x-derivative at the keypoint location within the window.\"\"\"\n","    x, y = int(keypoint[0]), int(keypoint[1])\n","    sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5)\n","    return sobel_x[y - winSize[1]//2:y + winSize[1]//2 + 1, x - winSize[0]//2:x + winSize[0]//2 + 1]\n","\n","\n","def get_derivative_y(img, keypoint, winSize):\n","    \"\"\"Compute y-derivative at the keypoint location within the window.\"\"\"\n","    x, y = int(keypoint[0]), int(keypoint[1])\n","    sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5)\n","    return sobel_y[y - winSize[1]//2:y + winSize[1]//2 + 1, x - winSize[0]//2:x + winSize[0]//2 + 1]\n","\n","\n","def get_derivative_t(prevImg, nextImg, keypoint, winSize):\n","    \"\"\"Compute temporal derivative at the keypoint location.\"\"\"\n","    x, y = int(keypoint[0]), int(keypoint[1])\n","    patch_prev = prevImg[y - winSize[1]//2:y + winSize[1]//2 + 1, x - winSize[0]//2:x + winSize[0]//2 + 1]\n","    patch_next = nextImg[y - winSize[1]//2:y + winSize[1]//2 + 1, x - winSize[0]//2:x + winSize[0]//2 + 1]\n","    return patch_next - patch_prev\n","\n","\n","def my_calcOpticalFlowPyrLK(prevImg, nextImg, prevPts, winSize):\n","    nextPts = []\n","    for keypoint in prevPts:\n","        keypoint = keypoint[0]\n","        dx = get_derivative_x(prevImg, keypoint, winSize)\n","        dy = get_derivative_y(prevImg, keypoint, winSize)\n","        dt = get_derivative_t(prevImg, nextImg, keypoint, winSize)\n","\n","        # Construct A and b matrices\n","        A = np.vstack((dx.flatten(), dy.flatten())).T\n","        b = -dt.flatten()\n","\n","        # Solve for p using least squares\n","        p, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n","\n","        # Update keypoint position\n","        new_x = keypoint[0] + p[0]\n","        new_y = keypoint[1] + p[1]\n","        nextPts.append([new_x, new_y])\n","\n","    return np.expand_dims(np.stack(nextPts), axis=1)"]},{"cell_type":"code","source":["video_path='data/slow_traffic_small.mp4'\n","cap = cv2.VideoCapture(video_path)\n","length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fps    = cap.get(cv2.CAP_PROP_FPS)\n","\n","fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n","out = cv2.VideoWriter('output/my_LK.mp4', fourcc, fps, (width, height))\n","\n","# params for ShiTomasi corner detection\n","feature_params = dict(\n","    maxCorners = 100,\n","    qualityLevel = 0.3,\n","    minDistance = 7,\n","    blockSize = 7,\n",")\n","# Create some random colors\n","color = np.random.randint(0, 255, (100, 3))\n","# Take first frame and find corners in it\n","ret, old_frame = cap.read()\n","old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n","p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n","\n","# Create a mask image for drawing purposes\n","mask = np.zeros_like(old_frame)\n","for i in tqdm(range(length)):\n","    ret, frame = cap.read()\n","    if not ret:\n","        print('No frames grabbed!')\n","        break\n","\n","    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","    # calculate optical flow\n","    p1 = my_calcOpticalFlowPyrLK(\n","        prevImg=old_gray,\n","        nextImg=frame_gray,\n","        prevPts=p0,\n","        winSize=(15, 15)\n","    )\n","\n","    # draw the tracks\n","    for i, (new, old) in enumerate(zip(p1, p0)):\n","        a, b = new.ravel()\n","        c, d = old.ravel()\n","        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n","        frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n","\n","    img = cv2.add(frame, mask)\n","    # Now update the previous frame and previous points\n","    old_gray = frame_gray.copy()\n","    p0 = p1.reshape(-1, 1, 2)\n","\n","    out.write(img)\n","\n","cap.release()\n","out.release()"],"metadata":{"id":"2Stt-34X--a6","executionInfo":{"status":"ok","timestamp":1713208919531,"user_tz":-180,"elapsed":41324,"user":{"displayName":"Julia Bel","userId":"09344534935963523050"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fbaf8cdf-50bb-4ce2-9f10-816ea2620568"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 913/914 [00:39<00:00, 22.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["No frames grabbed!\n"]}]},{"cell_type":"code","source":["IPython.display.Video('output/my_LK.mp4')"],"metadata":{"colab":{"resources":{"http://localhost:8080/output/my_LK.mp4":{"data":"CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K","ok":false,"headers":[["content-length","1449"],["content-type","text/html; charset=utf-8"]],"status":404,"status_text":""}},"base_uri":"https://localhost:8080/","height":171},"id":"j-fmarhKIZKv","executionInfo":{"status":"ok","timestamp":1713209066901,"user_tz":-180,"elapsed":311,"user":{"displayName":"Julia Bel","userId":"09344534935963523050"}},"outputId":"017af1b8-77f1-49a6-c30a-a14d3d33e522"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Video object>"],"text/html":["<video src=\"output/my_LK.mp4\" controls  >\n","      Your browser does not support the <code>video</code> element.\n","    </video>"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"VQopEVhe_Jxi"},"source":["### Релизация OpenCV - cv2.calcOpticalFlowPyrLK"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cRx9XKJj_Jxj","executionInfo":{"status":"ok","timestamp":1713209077726,"user_tz":-180,"elapsed":7268,"user":{"displayName":"Julia Bel","userId":"09344534935963523050"}},"outputId":"46cdad2c-d5db-4ae1-d4d7-67bd36b5e409"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 913/914 [00:06<00:00, 150.04it/s]"]},{"output_type":"stream","name":"stdout","text":["No frames grabbed!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["video_path='data/slow_traffic_small.mp4'\n","cap = cv2.VideoCapture(video_path)\n","length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fps    = cap.get(cv2.CAP_PROP_FPS)\n","\n","fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n","out = cv2.VideoWriter('output/LK.mp4', fourcc, fps, (width, height))\n","\n","# params for ShiTomasi corner detection\n","feature_params = dict(\n","    maxCorners = 100,\n","    qualityLevel = 0.3,\n","    minDistance = 7,\n","    blockSize = 7,\n",")\n","\n","# Parameters for lucas kanade optical flow\n","lk_params = dict(\n","    winSize  = (15, 15),\n","    maxLevel = 2,\n","    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",")\n","# Create some random colors\n","color = np.random.randint(0, 255, (100, 3))\n","# Take first frame and find corners in it\n","ret, old_frame = cap.read()\n","old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n","p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n","# Create a mask image for drawing purposes\n","mask = np.zeros_like(old_frame)\n","for i in tqdm(range(length)):\n","\n","    ret, frame = cap.read()\n","\n","    if not ret:\n","        print('No frames grabbed!')\n","        break\n","\n","    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","    # calculate optical flow\n","    # see params here https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323\n","    p1, st, _ = cv2.calcOpticalFlowPyrLK(\n","        prevImg=old_gray,\n","        nextImg=frame_gray,\n","        prevPts=p0,\n","        nextPts=None,\n","        **lk_params,\n","    )\n","\n","    # Select good points where status is equal 1\n","    if p1 is not None:\n","        good_new = p1[st==1]\n","        good_old = p0[st==1]\n","\n","    # draw the tracks\n","    for i, (new, old) in enumerate(zip(good_new, good_old)):\n","        a, b = new.ravel()\n","        c, d = old.ravel()\n","        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n","        frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n","\n","    img = cv2.add(frame, mask)\n","    # Now update the previous frame and previous points\n","    old_gray = frame_gray.copy()\n","    p0 = good_new.reshape(-1, 1, 2)\n","\n","    out.write(img)\n","\n","cap.release()\n","out.release()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"resources":{"http://localhost:8080/output/LK.mp4":{"data":"CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K","ok":false,"headers":[["content-length","1449"],["content-type","text/html; charset=utf-8"]],"status":404,"status_text":""}},"base_uri":"https://localhost:8080/","height":171},"id":"0ao-ZlQK_Jxl","executionInfo":{"status":"ok","timestamp":1713209437479,"user_tz":-180,"elapsed":662,"user":{"displayName":"Julia Bel","userId":"09344534935963523050"}},"outputId":"6d57ecd9-f4cd-4e02-ac78-d971832eddde"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Video object>"],"text/html":["<video src=\"output/LK.mp4\" controls  >\n","      Your browser does not support the <code>video</code> element.\n","    </video>"]},"metadata":{},"execution_count":16}],"source":["IPython.display.Video('output/LK.mp4')"]},{"cell_type":"markdown","metadata":{"id":"mmSDJDRt_Jxm"},"source":["### Вопрос 2\n","\n","Какие проблемы в текущей реализации вы увидели при просмотре результирующего видео? Как их можно устранить?\n","\n","**Ответ:**  \n","Есть проблемы, связанные с неточностью определения и отслеживания, однако основная проблема: ключевые точки фиксируются только в начальный момент времени, поэтому новые объекты не отслеживаются. Это можно исправить путем обновления целевых точек, например, когда какие-либо объекты выходят за пределы поля видимости."]},{"cell_type":"markdown","metadata":{"id":"7jqlEo5-_Jxm"},"source":["### Задание 2\n","\n","Напишите код, устраняющий одну из проблем, покажите результат до/после."]},{"cell_type":"code","source":["video_path='data/slow_traffic_small.mp4'\n","cap = cv2.VideoCapture(video_path)\n","length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fps    = cap.get(cv2.CAP_PROP_FPS)\n","\n","fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n","out = cv2.VideoWriter('output/fixed_LK.mp4', fourcc, fps, (width, height))\n","\n","feature_params = dict(\n","    maxCorners = 100,\n","    qualityLevel = 0.3,\n","    minDistance = 7,\n","    blockSize = 7,\n",")\n","lk_params = dict(\n","    winSize  = (15, 15),\n","    maxLevel = 2,\n","    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",")\n","color = np.random.randint(0, 255, (100, 3))\n","ret, old_frame = cap.read()\n","old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n","p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n","mask = np.zeros_like(old_frame)\n","\n","for i in tqdm(range(length)):\n","    ret, frame = cap.read()\n","    if not ret:\n","        print('No frames grabbed!')\n","        break\n","\n","    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    p1, st, _ = cv2.calcOpticalFlowPyrLK(\n","        prevImg=old_gray,\n","        nextImg=frame_gray,\n","        prevPts=p0,\n","        nextPts=None,\n","        **lk_params,\n","    )\n","\n","    if p1 is not None:\n","        good_new = p1[st==1]\n","        good_old = p0[st==1]\n","\n","    for i, (new, old) in enumerate(zip(good_new, good_old)):\n","        a, b = new.ravel()\n","        c, d = old.ravel()\n","        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n","        frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n","    img = cv2.add(frame, mask)\n","\n","    if p1 is not None and len(good_new) > 0:\n","        old_gray = frame_gray.copy()\n","        p0 = good_new.reshape(-1, 1, 2)\n","\n","    # re-detect features periodically\n","    if len(p0) < feature_params['maxCorners'] // 2 and \\\n","        any([(p > old_frame.shape).all() for p in p0.ravel()]):\n","        p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n","\n","    out.write(img)\n","\n","cap.release()\n","out.release()"],"metadata":{"id":"Z5KGQSEkC-yu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713209167902,"user_tz":-180,"elapsed":11842,"user":{"displayName":"Julia Bel","userId":"09344534935963523050"}},"outputId":"0add3435-e450-4130-8976-3ed73d09315a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 913/914 [00:11<00:00, 79.67it/s]"]},{"output_type":"stream","name":"stdout","text":["No frames grabbed!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["IPython.display.Video('output/fixed_LK.mp4')"],"metadata":{"id":"3YzlI8nFly-0","colab":{"resources":{"http://localhost:8080/output/fixed_LK.mp4":{"data":"CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K","ok":false,"headers":[["content-length","1449"],["content-type","text/html; charset=utf-8"]],"status":404,"status_text":""}},"base_uri":"https://localhost:8080/","height":171},"executionInfo":{"status":"ok","timestamp":1713209169759,"user_tz":-180,"elapsed":349,"user":{"displayName":"Julia Bel","userId":"09344534935963523050"}},"outputId":"17cc5ad0-d921-49f2-95be-991284d66e43"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Video object>"],"text/html":["<video src=\"output/fixed_LK.mp4\" controls  >\n","      Your browser does not support the <code>video</code> element.\n","    </video>"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"A6r6l57V_Jxm"},"source":["## Farneback (dense)\n","\n","Метод Farneback носит несколько более глобальный характер, чем метод Лукаса-Канаде. Он опирается на предположение о том, что на всем изображении оптический поток будет достаточно гладким."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-qSxDbdO_Jxm","executionInfo":{"status":"ok","timestamp":1713209286403,"user_tz":-180,"elapsed":96919,"user":{"displayName":"Julia Bel","userId":"09344534935963523050"}},"outputId":"392e6128-5f17-47e4-8e92-858db351e900"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 913/914 [01:36<00:00,  9.45it/s]"]},{"output_type":"stream","name":"stdout","text":["No frames grabbed!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["cap = cv2.VideoCapture(video_path)\n","\n","length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fps    = cap.get(cv2.CAP_PROP_FPS)\n","\n","fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n","out = cv2.VideoWriter('output/Farneback.mp4', fourcc, fps, (width, height))\n","\n","ret, frame1 = cap.read()\n","prvs = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n","hsv = np.zeros_like(frame1)\n","hsv[..., 1] = 255\n","\n","for i in tqdm(range(length)):\n","\n","    ret, frame2 = cap.read()\n","\n","    if not ret:\n","        print('No frames grabbed!')\n","        break\n","\n","    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n","\n","    # see arguments here https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga5d10ebbd59fe09c5f650289ec0ece5af\n","    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n","    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n","    hsv[..., 0] = ang*180/np.pi/2\n","    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n","    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n","    prvs = next\n","\n","    out.write(bgr)\n","\n","cap.release()\n","out.release()"]},{"cell_type":"markdown","metadata":{"id":"yFPHs9Xv_Jxn"},"source":["Посмотрим, что получилось"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"resources":{"http://localhost:8080/output/Farneback.mp4":{"data":"CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K","ok":false,"headers":[["content-length","1449"],["content-type","text/html; charset=utf-8"]],"status":404,"status_text":""}},"base_uri":"https://localhost:8080/","height":171},"id":"hQFNKbL3_Jxn","executionInfo":{"status":"ok","timestamp":1713209431685,"user_tz":-180,"elapsed":298,"user":{"displayName":"Julia Bel","userId":"09344534935963523050"}},"outputId":"7cca0ecc-6a45-475a-e4fa-3dc0ac529bda"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.core.display.Video object>"],"text/html":["<video src=\"output/Farneback.mp4\" controls  >\n","      Your browser does not support the <code>video</code> element.\n","    </video>"]},"metadata":{},"execution_count":15}],"source":["IPython.display.Video('output/Farneback.mp4')"]},{"cell_type":"code","source":[],"metadata":{"id":"eP6QpOeVRFKz"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}